<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>KagariのBlog</title>
  
  
  <link href="https://kagari306.win/atom.xml" rel="self"/>
  
  <link href="https://kagari306.win/"/>
  <updated>2025-06-30T20:24:27.611Z</updated>
  <id>https://kagari306.win/</id>
  
  <author>
    <name>Kagari 306</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>星际蜗牛魔改NAS踩坑</title>
    <link href="https://kagari306.win/2025/07/01/%E6%98%9F%E9%99%85%E8%9C%97%E7%89%9B%E9%AD%94%E6%94%B9NAS%E8%B8%A9%E5%9D%91/"/>
    <id>https://kagari306.win/2025/07/01/%E6%98%9F%E9%99%85%E8%9C%97%E7%89%9B%E9%AD%94%E6%94%B9NAS%E8%B8%A9%E5%9D%91/</id>
    <published>2025-06-30T19:46:35.000Z</published>
    <updated>2025-06-30T20:24:27.611Z</updated>
    
    <content type="html"><![CDATA[<p>现在是东八区的 03:46 A.M. ，我正在写这篇文章。</p><p>刚折腾完NAS，无力截图，所以全都是口述，大家凑合着看吧。</p><p>有的地方可能还能找出两三张图，但是大部分都没有，网上倒是到处都是，但是我怕图片误导你们，所以我找不到实拍图的就不放了。</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>星际蜗牛魔改NAS，黑群晖系统，踩坑记录。</p><p>先说说我总共花了多少钱吧</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">主机: 星际蜗牛D版，整机，除了硬盘以外都有 280.00元</span><br><span class="line">12cm三线可调风扇：家里翻出来的。当时买了四把，共24.9元，只用了两把，剩下两把吃灰。 24.9/4=6.15元</span><br><span class="line">电源: 易衡FLEX 小1U 电源 250W 255.00元</span><br><span class="line">共计: 280.00 + 6.15 + 255.00 = 541.15元</span><br></pre></td></tr></table></figure><p>硬盘不计入，我整了两块4T和两块500G组了两个阵列，4T组raid1存点照片，500g组raid0做下载盘</p><p>这里顺带提一嘴，他自己带了个ZUMAX的150W电源，测了一下纹波大概在60-80mV，而我采购的易衡 FLEX 小1U 电源纹波大概在20-30mV</p><p>12v是最大120mv<br>12v-5v是最大50mv<br>易得:ZUMAX烧硬盘不烧cpu</p><p>然后又看了一下 发现他硬盘笼上接了俩个470uF的电容用于缓冲电源纹波，所以你要用的话硬盘会一点一点的坏道而不是直接烧</p><p>顺带，如果你不需要考虑噪音和功耗的话考虑一下下面的方案</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">主机: 5212M4带3008直通卡 380.00元</span><br><span class="line">cpu: E5-2620V4 * 2 = 9 * 2 = 18元</span><br><span class="line">内存：三星8G 2133 DDR4 = 72元</span><br><span class="line">共计：380 + 18 + 72 = 380 + 90 = 470元</span><br></pre></td></tr></table></figure><p>便宜，CPU还多了几个核，而且浪潮有12个硬盘槽，缺点就是2U的功耗和噪音不是寻常人家能接受的</p><h2 id="验货"><a href="#验货" class="headerlink" title="验货"></a>验货</h2><p>到货后开机，发现他已经被刷过了DMS。<br>那就省事了，挨个热插拔，发现四个硬盘槽都可以正常用。</p><p>这样就好了，收货，因为我要拆。</p><h2 id="拆机"><a href="#拆机" class="headerlink" title="拆机"></a>拆机</h2><p>这里我参考了 <a href="https://post.smzdm.com/p/av7ko4xn/">这篇文章</a><br>只有<code>前面板的4个固定螺帽</code>那里，我手上没有能伸进去的套筒。尖嘴钳打不开，喷了点wd40打开了。<br>拆开后发现上家装的风扇是2线的，而且是直接插大4D插口，改为3线后噪音明显下降<br>电源挺好换，只拆开壳子就能换，就是容易划手，我拆的时候手都划破了</p><h2 id="烧录系统"><a href="#烧录系统" class="headerlink" title="烧录系统"></a>烧录系统</h2><p>我以前用ARPL来着，前两天搜了一下发现现在流行 <code>rr.org</code> 了,遂尝试</p><p>然后出现一个很艹蛋的事情：进入系统就乱码，输出的啥都看不见，过了grub就是乱码。但是你进入rr的configure loader他又是正常的<br>这个问题后面再讲，咱们先不管</p><p>烧录工具就用Rufus，直接去 <a href="https://github.com/RROrg/rr">rr的官方仓库</a> 下载iso</p><p>我不用u盘引导进入群晖系统，所以给u盘烧了个Alpine Linux<br>烧完了diskgenius打开，给后面剩余空间分个区（别用ntfs和ext4，这俩一个linux下打不开一个windows下打不开。建议用胖32）<br>然后给iso拷贝进U盘后面剩余空间的分区，这就烧完了</p><h2 id="调整BIOS设置"><a href="#调整BIOS设置" class="headerlink" title="调整BIOS设置"></a>调整BIOS设置</h2><p>这里有个大坑。我不知道为什么他们都让改引导模式为 <code>Windows8.x</code> ，反正我在这卡了半天。上面提到的输出乱码和你后面会碰到的拔掉显示器就卡引导进不了系统都是这里的问题。调整为 <code>Windows7.x</code> 就没问题了。<br><img src="/uploads/2025-07-01--welcome_to_grub.png" alt="卡引导" title="Welcome to grub!"></p><p>如果需要 <code>WoL</code> 的话, 找到BIOS里面一个 <code>Onboard LAN</code>沾边的选项，我记得好像是叫 <del>板载网卡影响状态</del>， 改成 <code>Enabled</code> 就可以了，这一点和网上其他教程不一样，然后给丢电后恢复状态那个改为off就行了。</p><h2 id="安装系统"><a href="#安装系统" class="headerlink" title="安装系统"></a>安装系统</h2><p>我装了个msata进去，插上u盘，引导启动。</p><p>启动后mount &#x2F;dev&#x2F;sdbX &#x2F;mnt<br>挨个挂挂看看哪个是拷进去的iso<br>找到后直接dd if&#x3D;&#x2F;mnt&#x2F;rr.iso of&#x3D;&#x2F;dev&#x2F;sda bs&#x3D;4M</p><p>跑完之后重启，拔u盘，开机，再进就是rr了。</p><p>rr没什么好说的，就是正常流程，和ARPL一样。我选了DS1621+，你们看着选吧</p><p>再后面没啥好说的了，就是正常流程，装完系统，挂硬盘，组raid，装插件，完事。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><h3 id="关于输出乱码"><a href="#关于输出乱码" class="headerlink" title="关于输出乱码"></a>关于输出乱码</h3><p>我之前一直以为是grub的问题，但是后来发现是rr的问题，rr的grub是正常显示，你进系统后输出就是乱码</p><h3 id="关于显示器"><a href="#关于显示器" class="headerlink" title="关于显示器"></a>关于显示器</h3><p>我试过假负载，hdmi插显示器的时候就可以正常启动，插上hdmi假负载就启动不了<br>可能是我改了BIOS里设置的问题，这几天改的设置太多了，我也不知道哪里出的问题</p><h3 id="关于主板"><a href="#关于主板" class="headerlink" title="关于主板"></a>关于主板</h3><p>我发现主板上有一大堆预留焊盘</p><p><img src="/uploads/2025-07-01_sata.jpg" alt="SATA" title="掩耳盗铃"></p><p>RJ45一个，还有下面对应的芯片和供电。<br>SATA4个，对应的芯片没找见，被贴纸贴住了我一开始还没注意到<br>串口一个，没有芯片和供电，但是有预留焊盘，包括排针</p><p>我怀疑焊上就能用，但是我还没试过</p><h1 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h1><p>就这些吧 现在是04:24 A.M. 我要睡了，大家晚安。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;现在是东八区的 03:46 A.M. ，我正在写这篇文章。&lt;/p&gt;
&lt;p&gt;刚折腾完NAS，无力截图，所以全都是口述，大家凑合着看吧。&lt;/p&gt;
&lt;p&gt;有的地方可能还能找出两三张图，但是大部分都没有，网上倒是到处都是，但是我怕图片误导你们，所以我找不到实拍图的就不放了。&lt;/p&gt;</summary>
      
    
    
    
    <category term="折腾记录" scheme="https://kagari306.win/categories/%E6%8A%98%E8%85%BE%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="蜗牛星际" scheme="https://kagari306.win/tags/%E8%9C%97%E7%89%9B%E6%98%9F%E9%99%85/"/>
    
    <category term="modding" scheme="https://kagari306.win/tags/modding/"/>
    
    <category term="黑群晖" scheme="https://kagari306.win/tags/%E9%BB%91%E7%BE%A4%E6%99%96/"/>
    
    <category term="diy nas" scheme="https://kagari306.win/tags/diy-nas/"/>
    
    <category term="折腾记录" scheme="https://kagari306.win/tags/%E6%8A%98%E8%85%BE%E8%AE%B0%E5%BD%95/"/>
    
    <category term="踩坑" scheme="https://kagari306.win/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>AttributeError: module &#39;tensorflow&#39; has no attribute &#39;compat&#39;</title>
    <link href="https://kagari306.win/2025/01/17/AttributeError-module-tensorflow-has-no-attribute-compat/"/>
    <id>https://kagari306.win/2025/01/17/AttributeError-module-tensorflow-has-no-attribute-compat/</id>
    <published>2025-01-17T07:09:56.000Z</published>
    <updated>2025-01-17T07:17:45.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AttributeError-module-‘tensorflow’-has-no-attribute-‘compat’"><a href="#AttributeError-module-‘tensorflow’-has-no-attribute-‘compat’" class="headerlink" title="AttributeError: module ‘tensorflow’ has no attribute ‘compat’"></a>AttributeError: module ‘tensorflow’ has no attribute ‘compat’</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在运行代码时，出现如下错误：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">**balabala**</span><br><span class="line">AttributeError: module <span class="string">&#x27;tensorflow&#x27;</span> has no attribute <span class="string">&#x27;compat&#x27;</span></span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="来自tensorflow的github-issue"><a href="#来自tensorflow的github-issue" class="headerlink" title="来自tensorflow的github issue"></a>来自<a href="https://github.com/tensorflow/tensorflow/issues/40422">tensorflow的github issue</a></h3><p>ISSUE FIXED for me</p><p>Indeed the command “conda install tensorflow-gpu&#x3D;&#x3D;2.1.0” installed version 2.2.0 of tensorflow-estimator.<br>After “conda install tensorflow-estimator&#x3D;&#x3D;2.1.0” everything works fine</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;AttributeError-module-‘tensorflow’-has-no-attribute-‘compat’&quot;&gt;&lt;a href=&quot;#AttributeError-module-‘tensorflow’-has-no-attribute-‘compat’&quot; class=&quot;headerlink&quot; title=&quot;AttributeError: module ‘tensorflow’ has no attribute ‘compat’&quot;&gt;&lt;/a&gt;AttributeError: module ‘tensorflow’ has no attribute ‘compat’&lt;/h1&gt;&lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;p&gt;在运行代码时，出现如下错误：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;**balabala**&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;AttributeError: module &lt;span class=&quot;string&quot;&gt;&amp;#x27;tensorflow&amp;#x27;&lt;/span&gt; has no attribute &lt;span class=&quot;string&quot;&gt;&amp;#x27;compat&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="problem" scheme="https://kagari306.win/categories/problem/"/>
    
    
    <category term="problem" scheme="https://kagari306.win/tags/problem/"/>
    
    <category term="tensorflow" scheme="https://kagari306.win/tags/tensorflow/"/>
    
    <category term="conda" scheme="https://kagari306.win/tags/conda/"/>
    
    <category term="python" scheme="https://kagari306.win/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。</title>
    <link href="https://kagari306.win/2025/01/14/wsl-%E6%A3%80%E6%B5%8B%E5%88%B0-localhost-%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%EF%BC%8C%E4%BD%86%E6%9C%AA%E9%95%9C%E5%83%8F%E5%88%B0-WSL%E3%80%82NAT-%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84-WSL-%E4%B8%8D%E6%94%AF%E6%8C%81-localhost-%E4%BB%A3%E7%90%86%E3%80%82/"/>
    <id>https://kagari306.win/2025/01/14/wsl-%E6%A3%80%E6%B5%8B%E5%88%B0-localhost-%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%EF%BC%8C%E4%BD%86%E6%9C%AA%E9%95%9C%E5%83%8F%E5%88%B0-WSL%E3%80%82NAT-%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84-WSL-%E4%B8%8D%E6%94%AF%E6%8C%81-localhost-%E4%BB%A3%E7%90%86%E3%80%82/</id>
    <published>2025-01-13T16:09:43.000Z</published>
    <updated>2025-01-17T07:10:54.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="wsl-检测到-localhost-代理配置，但未镜像到-WSL。NAT-模式下的-WSL-不支持-localhost-代理。"><a href="#wsl-检测到-localhost-代理配置，但未镜像到-WSL。NAT-模式下的-WSL-不支持-localhost-代理。" class="headerlink" title="wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。"></a>wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。</h1><p>新配置完wsl之后，启动WSL的时候出现了一个提示</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">wsl: 检测到 <span class="title">localhost</span> 代理配置，但未镜像到 <span class="title">WSL</span>。</span></span><br><span class="line"><span class="function"><span class="title">NAT</span> 模式下的 <span class="title">WSL</span> 不支持 <span class="title">localhost</span> 代理。</span></span><br></pre></td></tr></table></figure><span id="more"></span><p>遂google,得知解决方法如下</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>在Windows中的<code>C:\Users\&lt;your_username&gt;</code>目录下创建一个<code>.wslconfig</code>文件，然后在文件中写入如下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[experimental]</span><br><span class="line">autoMemoryReclaim=gradual  </span><br><span class="line">networkingMode=mirrored</span><br><span class="line">dnsTunneling=true</span><br><span class="line">firewall=true</span><br><span class="line">autoProxy=true</span><br></pre></td></tr></table></figure><p>然后用wsl –shutdown关闭WSL，之后再重启，问题就解决了</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;wsl-检测到-localhost-代理配置，但未镜像到-WSL。NAT-模式下的-WSL-不支持-localhost-代理。&quot;&gt;&lt;a href=&quot;#wsl-检测到-localhost-代理配置，但未镜像到-WSL。NAT-模式下的-WSL-不支持-localhost-代理。&quot; class=&quot;headerlink&quot; title=&quot;wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。&quot;&gt;&lt;/a&gt;wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。&lt;/h1&gt;&lt;p&gt;新配置完wsl之后，启动WSL的时候出现了一个提示&lt;/p&gt;
&lt;figure class=&quot;highlight cmd&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;wsl: 检测到 &lt;span class=&quot;title&quot;&gt;localhost&lt;/span&gt; 代理配置，但未镜像到 &lt;span class=&quot;title&quot;&gt;WSL&lt;/span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;NAT&lt;/span&gt; 模式下的 &lt;span class=&quot;title&quot;&gt;WSL&lt;/span&gt; 不支持 &lt;span class=&quot;title&quot;&gt;localhost&lt;/span&gt; 代理。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="problem" scheme="https://kagari306.win/categories/problem/"/>
    
    
    <category term="windows" scheme="https://kagari306.win/tags/windows/"/>
    
    <category term="os" scheme="https://kagari306.win/tags/os/"/>
    
    <category term="wsl" scheme="https://kagari306.win/tags/wsl/"/>
    
    <category term="代理" scheme="https://kagari306.win/tags/%E4%BB%A3%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>autodl服务器抢购脚本</title>
    <link href="https://kagari306.win/2025/01/14/autodl%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8A%A2%E8%B4%AD%E8%84%9A%E6%9C%AC/"/>
    <id>https://kagari306.win/2025/01/14/autodl%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8A%A2%E8%B4%AD%E8%84%9A%E6%9C%AC/</id>
    <published>2025-01-13T16:02:30.000Z</published>
    <updated>2025-01-13T16:07:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近autodl的gpu有点难抢，所以写了个脚本，自动抢gpu）<br>实际上也没什么技术含量，就是模拟点击，然后判断价格是否在指定区间内，如果是就点击购买，否则就跳过<br>复制代码贴到f12的console里，然后按回车就可以自动抢购了</p><span id="more"></span><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> money_range = [<span class="number">0.5</span>,<span class="number">0.66</span>]; <span class="comment">// 设置价格区间（直接修改数字就行,这里是抢1080和TITAN Xp）</span></span><br><span class="line"><span class="keyword">var</span> region_range = [<span class="string">&#x27;重庆A区&#x27;</span>,<span class="string">&#x27;北京B区&#x27;</span>, <span class="string">&#x27;北京A区 H20&#x27;</span>, <span class="string">&#x27;佛山区&#x27;</span>, <span class="string">&#x27;内蒙A区&#x27;</span>]; <span class="comment">// 设置过滤地区（这个列表是排除在外的地区列表）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> congrats = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">var</span> node_list = <span class="variable language_">document</span>.<span class="title function_">querySelector</span>(<span class="string">&quot;.list-filter .filter-item .el-radio-group&quot;</span>).<span class="property">children</span>;</span><br><span class="line"><span class="keyword">var</span> start = <span class="keyword">function</span> <span class="title function_">start</span>(<span class="params">i</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (congrats) <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">if</span> (region_range.<span class="title function_">indexOf</span>(node_list[i].<span class="property">textContent</span>.<span class="title function_">trim</span>()) !== -<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= node_list.<span class="property">length</span> - <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="title function_">start</span>(<span class="number">0</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="title function_">start</span>(++i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">var</span> node = node_list[i];</span><br><span class="line">  node.<span class="title function_">click</span>();</span><br><span class="line">  <span class="keyword">var</span> timer = <span class="built_in">setTimeout</span>(<span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> _document$querySelect;</span><br><span class="line">    <span class="keyword">var</span> num = ((_document$querySelect = <span class="variable language_">document</span>.<span class="title function_">querySelector</span>(<span class="string">&quot;.pay-wrap .pay-right .price .sum&quot;</span>).<span class="property">children</span>[<span class="number">1</span>].<span class="title function_">getElementsByClassName</span>(<span class="string">&quot;num&quot;</span>)[<span class="number">0</span>]) === <span class="literal">null</span> || _document$querySelect === <span class="keyword">void</span> <span class="number">0</span> ? <span class="keyword">void</span> <span class="number">0</span> : _document$querySelect.<span class="property">textContent</span>) || -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="title class_">Number</span>(num) &gt;= money_range[<span class="number">0</span>] &amp;&amp; <span class="title class_">Number</span>(num) &lt;= money_range[<span class="number">1</span>]) &#123;</span><br><span class="line">      <span class="variable language_">document</span>.<span class="title function_">querySelector</span>(<span class="string">&quot;.operation .el-button--primary&quot;</span>).<span class="title function_">click</span>();</span><br><span class="line">      congrats = <span class="literal">true</span>;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;恭喜！抢到了&quot;</span>);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(node.<span class="property">textContent</span> + <span class="string">&quot;暂时没有，下一个&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= node_list.<span class="property">length</span> - <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="title function_">start</span>(<span class="number">0</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="title function_">start</span>(++i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">clearTimeout</span>(timer)</span><br><span class="line">  &#125;, <span class="number">1000</span>);</span><br><span class="line">&#125;;</span><br><span class="line"><span class="title function_">start</span>(<span class="number">0</span>);</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近autodl的gpu有点难抢，所以写了个脚本，自动抢gpu）&lt;br&gt;实际上也没什么技术含量，就是模拟点击，然后判断价格是否在指定区间内，如果是就点击购买，否则就跳过&lt;br&gt;复制代码贴到f12的console里，然后按回车就可以自动抢购了&lt;/p&gt;</summary>
    
    
    
    <category term="script" scheme="https://kagari306.win/categories/script/"/>
    
    
    <category term="code" scheme="https://kagari306.win/tags/code/"/>
    
    <category term="javascript" scheme="https://kagari306.win/tags/javascript/"/>
    
    <category term="autodl" scheme="https://kagari306.win/tags/autodl/"/>
    
    <category term="服务器" scheme="https://kagari306.win/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>error: ‘AT_CHECK’ was not declared in this scope</title>
    <link href="https://kagari306.win/2024/12/31/error-%E2%80%98AT-CHECK%E2%80%99-was-not-declared-in-this-scope/"/>
    <id>https://kagari306.win/2024/12/31/error-%E2%80%98AT-CHECK%E2%80%99-was-not-declared-in-this-scope/</id>
    <published>2024-12-30T17:13:23.000Z</published>
    <updated>2025-01-17T07:11:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天安装复现某个包含CUDA依赖的老cpp项目的时候编译报错 <code>error: ‘AT_CHECK’ was not declared in this scope</code></p><span id="more"></span><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">...无用信息</span><br><span class="line">/root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_cuda.cpp:4:23: error: ‘AT_CHECK’ was not declared <span class="keyword">in</span> this scope</span><br><span class="line"> <span class="comment">#define CHECK_CUDA(x) AT_CHECK(x.type().is_cuda(), #x, &quot; must be a CUDAtensor &quot;)</span></span><br><span class="line">                       ^</span><br><span class="line">/root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_cuda.cpp:9:3: note: <span class="keyword">in</span> expansion of macro ‘CHECK_CUDA’</span><br><span class="line">   CHECK_CUDA(dets);</span><br><span class="line">   ^~~~~~~~~~</span><br><span class="line">/root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_cuda.cpp:4:23: note: suggested alternative: ‘DCHECK’</span><br><span class="line"> <span class="comment">#define CHECK_CUDA(x) AT_CHECK(x.type().is_cuda(), #x, &quot; must be a CUDAtensor &quot;)</span></span><br><span class="line">                       ^</span><br><span class="line">/root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_cuda.cpp:9:3: note: <span class="keyword">in</span> expansion of macro ‘CHECK_CUDA’</span><br><span class="line">   CHECK_CUDA(dets);</span><br><span class="line">   ^~~~~~~~~~</span><br><span class="line">[2/2] /usr/local/cuda/bin/nvcc -DWITH_CUDA -I/root/miniconda3/lib/python3.8/site-packages/torch/include -I/root/miniconda3/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/root/miniconda3/lib/python3.8/site-packages/torch/include/TH -I/root/miniconda3/lib/python3.8/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/miniconda3/include/python3.8 -c -c /root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_kernel.cu -o /root/autodl-tmp/OrientedRepPoints_DOTA/build/temp.linux-x86_64-3.8/mmdet/ops/nms/src/nms_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options <span class="string">&#x27;&#x27;</span><span class="string">&quot;&#x27;&quot;</span><span class="string">&#x27;-fPIC&#x27;</span><span class="string">&quot;&#x27;&quot;</span><span class="string">&#x27;&#x27;</span> -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nms_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=<span class="built_in">arch</span>=compute_75,code=sm_75 -std=c++14</span><br><span class="line">/root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_kernel.cu: In <span class="keyword">function</span> ‘at::Tensor nms_cuda(at::Tensor, <span class="built_in">float</span>)’:</span><br><span class="line">/root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_kernel.cu:77:62: warning: ‘at::DeprecatedTypeProperties&amp; at::Tensor::<span class="built_in">type</span>() const’ is deprecated: Tensor.<span class="built_in">type</span>() is deprecated. Instead use Tensor.options(), <span class="built_in">which</span> <span class="keyword">in</span> many cases (e.g. <span class="keyword">in</span> a constructor) is a drop-in replacement. If you were using data from <span class="built_in">type</span>(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]</span><br><span class="line">   AT_ASSERTM(boxes.type().is_cuda(), <span class="string">&quot;boxes must be a CUDA tensor&quot;</span>);</span><br><span class="line">                                                              ^</span><br><span class="line">/root/miniconda3/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:277:1: note: declared here</span><br><span class="line">   DeprecatedTypeProperties &amp; <span class="built_in">type</span>() const &#123;</span><br><span class="line"> ^ ~~</span><br><span class="line">/root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_kernel.cu:86:50: warning: ‘T* at::Tensor::data() const [with T = <span class="built_in">float</span>]’ is deprecated: Tensor.data&lt;T&gt;() is deprecated. Please use Tensor.data_ptr&lt;T&gt;() instead. [-Wdeprecated-declarations]</span><br><span class="line">   scalar_t* boxes_dev = boxes_sorted.data&lt;scalar_t&gt;();</span><br><span class="line">                                                  ^</span><br><span class="line">/root/miniconda3/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:363:1: note: declared here</span><br><span class="line">   T * data() const &#123;</span><br><span class="line"> ^ ~~</span><br><span class="line">/root/autodl-tmp/OrientedRepPoints_DOTA/mmdet/ops/nms/src/nms_kernel.cu:117:46: warning: ‘T* at::Tensor::data() const [with T = long int]’ is deprecated: Tensor.data&lt;T&gt;() is deprecated. Please use Tensor.data_ptr&lt;T&gt;() instead. [-Wdeprecated-declarations]</span><br><span class="line">   int64_t* keep_out = keep.data&lt;int64_t&gt;();</span><br><span class="line">                                              ^</span><br><span class="line">/root/miniconda3/lib/python3.8/site-packages/torch/include/ATen/core/TensorBody.h:363:1: note: declared here</span><br><span class="line">   T * data() const &#123;</span><br><span class="line"> ^ ~~</span><br><span class="line">ninja: build stopped: subcommand failed.</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/torch/utils/cpp_extension.py&quot;</span>, line 1516, <span class="keyword">in</span> _run_ninja_build</span><br><span class="line">    subprocess.run(</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/subprocess.py&quot;</span>, line 516, <span class="keyword">in</span> run</span><br><span class="line">    raise CalledProcessError(retcode, process.args,</span><br><span class="line">subprocess.CalledProcessError: Command <span class="string">&#x27;[&#x27;</span>ninja<span class="string">&#x27;, &#x27;</span>-v<span class="string">&#x27;]&#x27;</span> returned non-zero <span class="built_in">exit</span> status 1.</span><br><span class="line"></span><br><span class="line">The above exception was the direct cause of the following exception:</span><br><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;setup.py&quot;</span>, line 194, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    setup(</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/setuptools/__init__.py&quot;</span>, line 153, <span class="keyword">in</span> setup</span><br><span class="line">    <span class="built_in">return</span> distutils.core.setup(**attrs)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/core.py&quot;</span>, line 148, <span class="keyword">in</span> setup</span><br><span class="line">    dist.run_commands()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/dist.py&quot;</span>, line 966, <span class="keyword">in</span> run_commands</span><br><span class="line">    self.run_command(cmd)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/dist.py&quot;</span>, line 985, <span class="keyword">in</span> run_command</span><br><span class="line">    cmd_obj.run()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/setuptools/command/install.py&quot;</span>, line 67, <span class="keyword">in</span> run</span><br><span class="line">    self.do_egg_install()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/setuptools/command/install.py&quot;</span>, line 109, <span class="keyword">in</span> do_egg_install</span><br><span class="line">    self.run_command(<span class="string">&#x27;bdist_egg&#x27;</span>)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/cmd.py&quot;</span>, line 313, <span class="keyword">in</span> run_command</span><br><span class="line">    self.distribution.run_command(<span class="built_in">command</span>)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/dist.py&quot;</span>, line 985, <span class="keyword">in</span> run_command</span><br><span class="line">    cmd_obj.run()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/setuptools/command/bdist_egg.py&quot;</span>, line 164, <span class="keyword">in</span> run</span><br><span class="line">    cmd = self.call_command(<span class="string">&#x27;install_lib&#x27;</span>, warn_dir=0)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/setuptools/command/bdist_egg.py&quot;</span>, line 150, <span class="keyword">in</span> call_command</span><br><span class="line">    self.run_command(cmdname)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/cmd.py&quot;</span>, line 313, <span class="keyword">in</span> run_command</span><br><span class="line">    self.distribution.run_command(<span class="built_in">command</span>)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/dist.py&quot;</span>, line 985, <span class="keyword">in</span> run_command</span><br><span class="line">    cmd_obj.run()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/setuptools/command/install_lib.py&quot;</span>, line 11, <span class="keyword">in</span> run</span><br><span class="line">    self.build()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/command/install_lib.py&quot;</span>, line 107, <span class="keyword">in</span> build</span><br><span class="line">    self.run_command(<span class="string">&#x27;build_ext&#x27;</span>)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/cmd.py&quot;</span>, line 313, <span class="keyword">in</span> run_command</span><br><span class="line">    self.distribution.run_command(<span class="built_in">command</span>)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/dist.py&quot;</span>, line 985, <span class="keyword">in</span> run_command</span><br><span class="line">    cmd_obj.run()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/setuptools/command/build_ext.py&quot;</span>, line 79, <span class="keyword">in</span> run</span><br><span class="line">    _build_ext.run(self)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/command/build_ext.py&quot;</span>, line 340, <span class="keyword">in</span> run</span><br><span class="line">    self.build_extensions()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/torch/utils/cpp_extension.py&quot;</span>, line 653, <span class="keyword">in</span> build_extensions</span><br><span class="line">    build_ext.build_extensions(self)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/command/build_ext.py&quot;</span>, line 449, <span class="keyword">in</span> build_extensions</span><br><span class="line">    self._build_extensions_serial()</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/command/build_ext.py&quot;</span>, line 474, <span class="keyword">in</span> _build_extensions_serial</span><br><span class="line">    self.build_extension(ext)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/setuptools/command/build_ext.py&quot;</span>, line 196, <span class="keyword">in</span> build_extension</span><br><span class="line">    _build_ext.build_extension(self, ext)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/Cython/Distutils/build_ext.py&quot;</span>, line 135, <span class="keyword">in</span> build_extension</span><br><span class="line">    super(build_ext, self).build_extension(ext)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/distutils/command/build_ext.py&quot;</span>, line 528, <span class="keyword">in</span> build_extension</span><br><span class="line">    objects = self.compiler.compile(sources,</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/torch/utils/cpp_extension.py&quot;</span>, line 473, <span class="keyword">in</span> unix_wrap_ninja_compile</span><br><span class="line">    _write_ninja_file_and_compile_objects(</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/torch/utils/cpp_extension.py&quot;</span>, line 1233, <span class="keyword">in</span> _write_ninja_file_and_compile_objects</span><br><span class="line">    _run_ninja_build(</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.8/site-packages/torch/utils/cpp_extension.py&quot;</span>, line 1538, <span class="keyword">in</span> _run_ninja_build</span><br><span class="line">    raise RuntimeError(message) from e</span><br><span class="line">RuntimeError: Error compiling objects <span class="keyword">for</span> extension</span><br></pre></td></tr></table></figure><p>首先看error,报错为 <code>error: ‘AT_CHECK’ was not declared in this scope</code><br>观察法得将 <code>AT_CHECK</code> 替换为 <code>TORCH_CHECK</code>就可以解决问题（（（（</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>由以上结果得bash指令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.cpp&quot;</span> -<span class="built_in">exec</span> sed -i <span class="string">&#x27;s/AT_CHECK/TORCH_CHECK/g&#x27;</span> &#123;&#125; \;</span><br></pre></td></tr></table></figure><p>运行后重新编译</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py build_ext --inplace</span><br></pre></td></tr></table></figure><p>编译通过，轻松秒杀</p><h2 id="错误原因"><a href="#错误原因" class="headerlink" title="错误原因"></a>错误原因</h2><p>该错误源于 <code>PyTorch</code> 和 <code>CUDA</code> 代码中已弃用且不兼容的宏和 API 使用。（人话，代码放过期了</p><p>在现代 <code>PyTorch</code> 版本中 <code>AT_CHECK</code> 已被替换为 <code>TORCH_CHECK</code>，并且一些张量方法（如）<code>.data&lt;T&gt;()</code> 已被弃用。<br>所以说只要把 <code>AT_CHECK</code> 统一换成 <code>TORCH_CHECK</code> 就可以解决这个问题了</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天安装复现某个包含CUDA依赖的老cpp项目的时候编译报错 &lt;code&gt;error: ‘AT_CHECK’ was not declared in this scope&lt;/code&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="problem" scheme="https://kagari306.win/categories/problem/"/>
    
    
    <category term="problem" scheme="https://kagari306.win/tags/problem/"/>
    
    <category term="python" scheme="https://kagari306.win/tags/python/"/>
    
    <category term="code" scheme="https://kagari306.win/tags/code/"/>
    
    <category term="cuda" scheme="https://kagari306.win/tags/cuda/"/>
    
    <category term="cpp" scheme="https://kagari306.win/tags/cpp/"/>
    
  </entry>
  
  <entry>
    <title>The detected CUDA version (x.x) mismatches the version that was used to compile PyTorch (x.x).</title>
    <link href="https://kagari306.win/2024/12/28/The-detected-CUDA-version-1x-x-mismatches-the-version-that-was-used-to-compile-PyTorch-1x-x/"/>
    <id>https://kagari306.win/2024/12/28/The-detected-CUDA-version-1x-x-mismatches-the-version-that-was-used-to-compile-PyTorch-1x-x/</id>
    <published>2024-12-27T16:30:53.000Z</published>
    <updated>2025-01-17T07:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天在安装某个库的时候报错</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ pip install -e .</span><br><span class="line">(一些无关紧要的输出)</span><br><span class="line">The detected CUDA version (10.2) mismatches the version that was used to compile</span><br><span class="line">PyTorch (11.7). Please make sure to use the same CUDA versions.</span><br><span class="line">(还是一些无关紧要的输出)</span><br></pre></td></tr></table></figure><p>但是我是用conda配置的环境，而且11.7的cudatoolkit和cudatoolkit-dev都已经安装了</p><span id="more"></span><p>由于我的<code>pytorch</code>是用 <a href="https://pytorch.org/get-started/previous-versions/">Previous PyTorch Versions</a> 给出的pip指令重新安装的对应cuda版本的torch,所以编译torch的cuda版本也是11.7</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ python -c <span class="string">&quot;import torch; print(torch.__version__)&quot;</span></span><br><span class="line">1.13.1+cu117</span><br></pre></td></tr></table></figure><p>也就是说问题出在pip忽略掉了目前conda环境内的cuda版本，从别的地方随便找了个cuda</p><p>遂google, 发现解决方案如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --no-build-isolation -e .</span><br></pre></td></tr></table></figure><p>成功安装</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天在安装某个库的时候报错&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ pip install -e .&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;(一些无关紧要的输出)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;The detected CUDA version (10.2) mismatches the version that was used to compile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;PyTorch (11.7). Please make sure to use the same CUDA versions.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;(还是一些无关紧要的输出)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;但是我是用conda配置的环境，而且11.7的cudatoolkit和cudatoolkit-dev都已经安装了&lt;/p&gt;</summary>
    
    
    
    <category term="problem" scheme="https://kagari306.win/categories/problem/"/>
    
    
    <category term="conda" scheme="https://kagari306.win/tags/conda/"/>
    
    <category term="python" scheme="https://kagari306.win/tags/python/"/>
    
    <category term="cuda" scheme="https://kagari306.win/tags/cuda/"/>
    
    <category term="pytorch" scheme="https://kagari306.win/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>PowerShell：因为在此系统上禁止运行脚本</title>
    <link href="https://kagari306.win/2024/12/28/PowerShell%EF%BC%9A%E5%9B%A0%E4%B8%BA%E5%9C%A8%E6%AD%A4%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%A6%81%E6%AD%A2%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC/"/>
    <id>https://kagari306.win/2024/12/28/PowerShell%EF%BC%9A%E5%9B%A0%E4%B8%BA%E5%9C%A8%E6%AD%A4%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%A6%81%E6%AD%A2%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC/</id>
    <published>2024-12-27T16:04:14.000Z</published>
    <updated>2025-01-17T07:11:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="报错详情"><a href="#报错详情" class="headerlink" title="报错详情"></a>报错详情</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PlaceHolder(先欠着)</span><br></pre></td></tr></table></figure><span id="more"></span><p>这个错误意味着执行策略很可能是 Restricted（默认设置）。</p><p><code>Restricted</code> 执行策略不允许任何脚本运行。<br><code>AllSigned</code> 和 <code>RemoteSigned</code> 执行策略可防止 Windows PowerShell 运行没有数字签名的脚本。</p><p>执行<code>get-executionpolicy</code>查看执行策略</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\WINDOWS\system32&gt; <span class="built_in">get-executionpolicy</span></span><br><span class="line">Restricted</span><br></pre></td></tr></table></figure><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>以管理员身份打开 PowerShell 执行 <code>set-executionpolicy remotesigned</code></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\WINDOWS\system32&gt; <span class="built_in">set-executionpolicy</span> remotesigned</span><br><span class="line"></span><br><span class="line">执行策略更改</span><br><span class="line">执行策略可帮助你防止执行不信任的脚本。更改执行策略可能会产生安全风险，如 https:/go.microsoft.com/fwlink/?LinkID=<span class="number">135170</span></span><br><span class="line">中的 about_Execution_Policies 帮助主题所述。是否要更改执行策略?</span><br><span class="line">[<span class="type">Y</span>] 是(Y)  [<span class="type">A</span>] 全是(A)  [<span class="type">N</span>] 否(N)  [<span class="type">L</span>] 全否(L)  [<span class="type">S</span>] 暂停(S)  [?] 帮助 (默认值为“N”): y</span><br><span class="line"><span class="built_in">PS</span> C:\WINDOWS\system32&gt; <span class="built_in">get-executionpolicy</span></span><br><span class="line">RemoteSigned</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;报错详情&quot;&gt;&lt;a href=&quot;#报错详情&quot; class=&quot;headerlink&quot; title=&quot;报错详情&quot;&gt;&lt;/a&gt;报错详情&lt;/h2&gt;&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;PlaceHolder(先欠着)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="problem" scheme="https://kagari306.win/categories/problem/"/>
    
    
    <category term="problem" scheme="https://kagari306.win/tags/problem/"/>
    
    <category term="powershell" scheme="https://kagari306.win/tags/powershell/"/>
    
    <category term="windows" scheme="https://kagari306.win/tags/windows/"/>
    
    <category term="os" scheme="https://kagari306.win/tags/os/"/>
    
  </entry>
  
</feed>
